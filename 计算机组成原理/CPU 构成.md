## CPU 构成

逻辑上，我们可以认为，CPU 其实就是由一堆寄存器组成的。而寄存器就是 CPU 内部，由多个触发器(Flip Flop)或者锁存器(Latches)组成的简单电路。

触发器和锁存器，其实就是两种不同原理的数字电路组成的逻辑门。

N 个触发器或者锁存器，就可以组成一个 N 位(Bit)的寄存器，能够保存 N 位的数据。比方说，我们用的 64 位 Intel 服务器，寄存器就是 64 位的。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gbemmgpntnj31gg0u0qc4.jpg" style="zoom: 33%;" />

一个 CPU 里面会有很多种不同功能的寄存器。这里给你介绍三种比较特殊的。

- **PC 寄存器(Program Counter Register), 也叫 指令地址寄存器(Instruction Address Register)** 用来存放下一条需要执行的计算机指令的内存地址；
- **指令寄存器(Instruction Register)** 用来存放当前正在执行的指令；
- **条件码寄存器(Status Register)** 用里面的一个个标记位(Flag)，存放 CPU 进行算术或者逻辑计算的结果。

除了这些特殊的寄存器，CPU 里面还有更多用来存储数据和内存地址的寄存器。这样的寄存器通常一类里面不止一个。我们通常根据存放的数据内容来给它们取名字，比如整数寄存器、浮点数寄存器、向量寄存器和地址寄存器等等。有些寄存器既可以存放数据，又能存放地址，我们就叫它通用寄存器。

实际上，一个程序执行的时候，CPU 会根据 PC 寄存器里的地址，从内存里面把需要执行的指令读取到指令寄存器里面执行，然后根据指令长度自增，开始顺序读取下一条指令。可以看到，一个程序的一条条指令，在内存里面是连续保存的，也会一条条顺序加载。

而有些特殊指令，比如 J 类指令，也就是跳转指令，会修改 PC 寄存器里面的地址值。这样，下一条要执行的指令就不是从内存里面顺序加载的了。

事实上，这些跳转指令的存在，也是我们可以在写程序的时候，使用 if…else 条件语句和 while/for 循环语句的原因。

## CPU 缓存

### SRAM

SRAM 被称为静态存储器，只有在通电状态，里面的数据才能保持存在。而一旦断电，里面的数据就会丢失。

在 SRAM 里，一个比特的数据，需要 6~8 个晶体管，所以 SRAM 的存储密度不高，同样的物理空间下，能够存储的数据有限。

正因为 SRAM 电路简单，所以访问速度非常快，CPU Cache(CPU 高速缓存) 便是用的 SRAM。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb24p1l1zwj30zk0qogmq.jpg" style="zoom: 33%;" />

在 CPU 里，通常会有 L1、L2、L3 这样三层高速缓存。

每个 CPU 核心都有一块属于自己的 L1 高速缓存，通常分成**指令缓存**和**数据缓存**，分开存放 CPU 使用的指令和数据。L1 Cache 往往嵌在 CPU 核心的内部，因此访问速度极快。

L2 Cache 同样是每个 CPU 核心都有的，不过它往往不在 CPU 核心的内部。所以 L2 Cache 的访问速度比 L1 稍微慢一些。

L3 Cache 通常由多个 CPU 核心共用，尺寸会更大一下，访问速度也更慢一些。

### DRAM

DRAM(Dynamic Random Access Memory, 动态随机存取存储器)被称为动态存储器，它需要靠不断的“刷新”，才能保持数据被存储起来。

DRAM 的一个比特，只需要一个晶体管和一个电容就能存储。所以，DRAM 在同样的物理空间下，能够存储的数据也就更多。

因为数据是存储在电容里的，电容会不断漏电，所以需要定时刷新充电，才能保持数据不丢失。

DRAM 的数据访问电路和刷新电路都比 SRAM 更复杂，所以访问延时也就更长。

### 存储器的层级结构

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2sqcbstvj30vq0gbgng.jpg" alt="存储器的层次关系图" style="zoom: 50%;" />

从 Cache、内存，到 SSD 和 HDD 硬盘，一台现代计算机中，就用上了所有这些存储器设备。其中，容量越小的设备速度越快，而且，CPU 并不是直接和每一种存储器设备打交道，而是每一种存储器设备，只和它相邻的存储设备打交道。比如，CPU Cache 是从内存里加载而来的，或者需要写回内存，并不会直接写回数据到硬盘，也不会直接从硬盘加载数据到 CPU Cache 中，而是先加载到内存，再从内存加载到 Cache 中。

这样，各个存储器只和相邻的一层存储器打交道，并且随着一层层向下，存储器的容量逐层增大，访问速度逐层变慢，而单位存储成本也逐层下降，也就构成了存储器层次结构。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gb2stwjmm1j30vq0gcdhm.jpg)



## 局部性原理

存储器中的**数据局部性原理**(Principle of Locality)，包括**时间局部性**(temporal locality)和**空间局部性**(spatial locality)。

- **时间局部性** 如果一个数据被访问了，那么它在短时间内还会被再次访问。

- **空间局部性** 如果一个数据被访问了，那么和它相邻的数据也很快会被访问。

有了时间局部性和空间局部性，我们不用再把所有数据都放在内存里，也不用都放在 HDD 硬盘上，而是把访问次数多的数据，放在贵但是快一点的存储器里，把访问次数少的数据，放在慢但是大一点的存储器里。这样组合使用内存、SSD 硬盘以及 HDD 硬盘，使得我们可以用最低的成本提供实际所需要的数据存储、管理和访问的需求。



## 高速缓存

```java
int[] arr = new int[64 * 1024 * 1024];


// 循环1
for (int i = 0; i < arr.length; i++) arr[i] *= 3;


// 循环2
for (int i = 0; i < arr.length; i += 16) arr[i] *= 3
  
```

在这段 Java 程序中，我们首先构造了一个 64×1024×1024 大小的整型数组。在循环 1 里，我们遍历整个数组，将数组中每一项的值变成了原来的 3 倍；在循环 2 里，我们每隔 16 个索引访问一个数组元素，将这一项的值变成了原来的 3 倍。

按道理来说，循环 2 只访问循环 1 中 1/16 的数组元素，只进行了循环 1 中 1/16 的乘法计算，那循环 2 花费的时间应该是循环 1 的 1/16 左右。但是实际上，循环 1 在我的电脑上运行需要 50 毫秒，循环 2 只需要 46 毫秒。这两个循环花费时间之差在 15% 之内。

为什么会有这 15% 的差异呢？这和我们今天要讲的 CPU Cache 有关。之前我们看到了内存和硬盘之间存在的巨大性能差异。在 CPU 眼里，内存也慢得不行。于是，聪明的工程师们就在 CPU 里面嵌入了 CPU Cache（高速缓存），来解决这一问题。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gb2t3f5bloj30vq0gv0t2.jpg)

在开始的程序中，运行程序的时间主要花在了将对应的数据从内存中读取出来，加载到 CPU Cache 中。CPU 从内存里读取数据到 CPU Cache 的过程中，是一小块一小块来读的，而不是按照单个数组元素来读取。这样一小块一小块的数据，在 CPU Cache 里，叫做 Cache Line(缓存块, 通常大小为 64 字节)。

### 直接映射 Cache

现代 CPU 进行数据读取的时候，无论数据是否已经存储在 Cache 中，CPU 始终会首先访问 Cache。只有当 CPU 在 Cache 中找不到数据的时候，才会去访问内存，并将读取到的数据写入 Cache 之中。当时间局部性原理起作用后，这个最近刚刚被访问的数据，会很快再次被访问。而 Cache 的访问速度远远快于内存，这样，CPU 花在等待内存访问上的时间就大大变短了。

那么，CPU 如何知道要访问的内存数据，存储在 Cache 的哪个位置呢？

这就用到了**直接映射 Cache(Direct Mapped Cache)**。

对于读取内存中的数据，我们首先拿到的是数据所在的内存块的地址。直接映射 Cache 采用的策略，就是确保任何一个内存块的地址，始终映射到一个固定的 CPU Cache 地址(Cache Line)。而这个映射关系，通常用 mod 运算来实现。

比如说，主内存被分为 0~31 号这样 32 个块(缓存块的数量通常会被设置为 2 的 N 次方)。我们一共有 8 个缓存快，用户想要访问第 21 号内存块，如果 21 号内存块内存在缓存快中的话，那它一定在 5 号缓存快(21 mod 8 = 5，实际计算中会直接取地址的 N 位)中。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2tijt7aaj30vq0m1753.jpg" style="zoom: 50%;" />

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2tkkd7saj30vq0l6q3m.jpg" style="zoom:50%;" />

如上图所示，5、13、21、29 内存块都对应着 5 号缓存块，那么假设想要获取 21 号内存块， CPU 如何知道 5 号缓存块里面的数据究竟是不是 21 号内存块呢？

在对应的缓存块中，我们会存储一个**组标记**(Tag)。这个组标记会记录，当前缓存块内存储的数据对应的内存块，而缓存块本身的地址表示访问地址的低 N 位，因此对应的组标记，只需要记录剩余的高地址即可。

除了组标记信息之外，缓存块中还有两个数据，一个是从主内存中加载来的实际存放的数据，另一个是**有效位**(valid bit)。它用来标记对应的缓存块中的数据是否有效。如果有效位是0，则表示 Cache Line 里没有数据，需要重新加载数据。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gb2tnpkyltj30vq0hqq49.jpg)

CPU 在读取数据的时候，并不是要读取整个 Block, 而是读取一个一个需要的整数。这样的数据，叫做 CPU 里的一个字(Word)。我们用偏移量(Offset)来表示这个字在整个 Block 里的位置。

**一个内存的访问地址，最终包括高位代表的组标记、低位代表的索引，以及在对应的 Data Block 中定位对应字的位置偏移量。**

而内存地址对应到 Cache 里的数据结构，则多了一个有效位和对应的数据，由“**索引 + 有效位 + 组标记 + 数据**” 组成。

如果内存中的数据已经在 CPU Cache 里了，那么一个内存地址的访问，就会经历这样 4 个步骤：

1. 根据内存地址的低位，计算在 Cache 中的索引；
2. 判断有效位，确认 Cache 中的数据是否是有效的；
3. 对比内存访问地址的高位，和 Cache 中的组标记，确认 Cache 中的数据就是我们要访问的内存数据，从 Cache Line 中读取到对应的数据块（Data Block）；
4. 根据内存地址的 Offset 位，从 Data Block 中，读取希望读取到的字。

如果在 2、3 这两个步骤中，CPU 发现，Cache 中的数据并不是要访问的内存地址的数据，那 CPU 就会访问内存，并把对应的 Block Data 更新到 Cache Line 中，同时更新对应的有效位和组标记的数据。

## CPU 高速缓存的写入

在一个多核 CPU 里，每一个 CPU 核里面，都有独立的属于自己的 L1、L2 Cache，然后多个 CPU 核共享一个 L3 Cache 和主内存。

因为 CPU Cache 的访问速度要比主内存快很多，而在 CPU Cache 里面，L1、L2 Cache 也要比 L3 Cache 快。所以 CPU 始终都是尽可能从 CPU Cache 中获取数据，而不是每次都要从主内存里面读取。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2w5gqkxej31570u00uo.jpg" style="zoom: 33%;" />

写入 Cache 的性能也要比写入主内存快，那么 CPU 如何将对 Cache 中数据的修改同步到主内存呢？

### 写直达(Write-Through)

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2w8zl9yxj30ry1jgdi0.jpg" style="zoom:33%;" />

最简单的一种写入策略，叫作写直达（Write-Through）。在这个策略里，每一次数据都要写入到主内存里面。在写直达的策略里面，写入前，我们会先去判断数据是否已经在 Cache 里面了。如果数据已经在 Cache 里面了，我们先把数据写入更新到 Cache 里面，再写入到主内存里面；如果数据不在 Cache 里，我们就只更新主内存。

写直达的这个策略很直观，但是问题也很明显，那就是这个策略很慢。无论数据是不是在 Cache 里面，我们都需要把数据写到主内存里面。这个方式就有点儿像 Java 中的 volatile 关键字，始终都要把数据同步到主内存里面。

### 写回(Write-Back)

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2wcx0k1cj30u01m6n2l.jpg" style="zoom:33%;" />

在 CPU Cache 的写入策略里，还有一种策略就叫作写回（Write-Back）。这个策略里，我们不再是每次都把数据写入到主内存，而是只写到 CPU Cache 里。只有当 CPU Cache 里面的数据要被“替换”的时候，我们才把数据写入到主内存里面去。

在用了写回这个策略之后，我们在加载内存数据到 Cache 里面的时候，也要多出一步同步脏 Cache 的动作。如果加载内存里面的数据到 Cache 的时候，发现 Cache Block 里面有脏标记，我们也要先把 Cache Block 里的数据写回到主内存，才能加载数据覆盖掉 Cache。

可以看到，在写回这个策略里，如果我们大量的操作，都能够命中缓存。那么大部分时间里，我们都不需要读写主内存，自然性能会比写直达的效果好很多。

## CPU 缓存一致性

假设两个 CPU 核都加在了同一个数据，但是 CPU 核心 1 修改了数据，为了性能问题，采用了写回策略，只更新了 L2 Cache，然后把 Cache Block 标记成脏的，这个时候数据其实并没有被同步到 L3 Cache 或者主内存里。1 号核心希望在这个 Cache Block 要被交换出去的时候，数据才写入到主内存。

此时 2 号核心尝试从内存里读取数据时，结果读到的是一个错误的数据。这个问题，就是所谓的缓存一致性问题。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2wob6ue9j31q40tm0ws.jpg" style="zoom:50%;" />

为了解决这个缓存不一致的问题，我们就需要有一种机制，来同步两个不同核心里面的缓存数据。

- **写传播** 在一个 CPU 核心里，Cache 数据更新时，必须能够传播到其他对应节点的 Cache Line 里。

- **事务的串行化** 在一个 CPU 核心里面的读取和写入，在其他的节点看起来，顺序应该是一样的。

### 总线嗅探机制

总线嗅探机制本质上就是把所有的读写请求通过总线(Bus)广播给所有的 CPU 核心，然后让各个核心去"嗅探"这些请求，再根据本地的情况做出响应。

总线本身就是一个特别适合广播进行数据传输的机制，所以总线嗅探这个办法也是我们日常使用的 Intel CPU 进行缓存一致性处理的解决方案。

基于总线嗅探机制，其实还可以分成很多种不同的缓存一致性协议。不过其中最常用的，就是 **MESI** 协议。

MESI 协议也叫**写失效**(Write Invalidate)协议。在写失效协议里，只有一个 CPU 核心负责写入数据，其他的核心，只是同步读取到这个写入。在这个 CPU 核心写入 Cache 之后，它会去广播一个“失效”请求告诉所有其他的 CPU 核心。其他的 CPU 核心，只是去判断自己是否也有一个“失效”版本的 Cache Block，然后把这个也标记成失效的就好了。

相比于写失效协议，还有一种叫做**写广播**（Write Broadcast）的协议。在那个协议里，一个写入请求广播到所有的 CPU 核心，同时更新各个核心里的 Cache。

写广播在实现上自然很简单，但是写广播需要占用更多的总线带宽。写失效只需要告诉其他的 CPU 核心，哪一个内存地址的缓存失效了，但是写广播还需要把对应的数据传输给其他 CPU 核心。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2xf639ilj30u01o1akq.jpg" alt="写失效" style="zoom:50%;" />

MESI 协议来自于 Cache Line 的四种不停的标记，分别是：

- **M** 代表已修改(Modified), Cache Block 里面的内容已经更新，但是还没有写回到主内存；
- **E** 代表独占(Exclusive)，对应的 Cache Line 只加载到当前 CPU 核所拥有的 Cache 里；
- **S** 代表共享(Shared)，同样的数据在多个 CPU 核的 Cache 里；
- **I** 代表已失效(Invalidated)，Cache Block 里的数据已经失效了，下次读取需要从主内存中读取。

在独占状态下，对应的 Cache Line 只加载到了当前 CPU 核所拥有的 Cache 里。其他的 CPU 核，并没有加载对应的数据到自己的 Cache 里。这个时候，如果要向独占的 Cache Block 写入数据，我们可以自由地写入数据，而不需要告知其他 CPU 核。

而在共享状态下，因为同样的数据在多个 CPU 核心的 Cache 里都有。所以，当我们想要更新 Cache 里面的数据的时候，不能直接修改，而是要先向所有的其他 CPU 核心广播一个请求，要求先把其他 CPU 核心里面的 Cache，都变成无效的状态，然后再更新当前 Cache 里面的数据。这个广播操作，一般叫作 RFO（Request For Ownership），也就是获取当前对应 Cache Block 数据的所有权。

整个 MESI 的状态，可以用一个有限状态机来表示它的状态流转。需要注意的是，对于不同状态触发的事件操作，可能来自于当前 CPU 核心，也可能来自总线里其他 CPU 核心广播出来的信号。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2yi5sa7dj30xb0u010s.jpg" style="zoom:50%;" />

## 上下文切换

Linux 是一个多任务操作系统，它支持远大于 CPU 数量的任务同时运行。当然，这些任务实际上并不是真的在同时运行，而是因为系统在很短的时间内，将 CPU 轮流分配给它们，造成多任务同时运行的错觉。

而在每个任务运行前，CPU 都需要知道任务从哪里加载、又从哪里开始运行，也就是说，需要系统事先帮它设置到 **CPU 寄存器和程序计数器(Program Counter, PC)**。

CPU 寄存器是 CPU 内置的容量小、但速度极快的内存。而程序计数器则是用来存储 CPU 正在执行的指令位置或者即将执行的下一条指令位置。他们都是 CPU 在运行任何任务前必须的依赖环境，因此也被叫作 **CPU 上下文**。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgrowz98qj30c609ljrk.jpg)

CPU 上下文切换，就是先把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的位置，运行新任务。

而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。



操作系统管理的任务包括进程、线程以及硬件中断(硬件通过触发信号，会导致中断处理程序的调用，也是一种常见的任务)。

所以，根据任务不同，CPU 的上下文切换就可以分为三种不同的场景，也就是**进程上下文切换**、**线程上下文切换**以及**中断上下文切换**。

### 进程上下文切换

Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。

- 内核空间（Ring 0）具有最高权限，可以直接访问所有资源；
- 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbguham5sjj308x08ojs1.jpg)

换个角度看，也就是说，进程既可以在用户空间运行，又可以在内核空间中运行。进程在用户空间运行时，被称为进程的用户态，而陷入内核空间的时候，被称为进程的内核态。

从用户态到内核态的转变，需要通过**系统调用**来完成。比如，当我们查看文件内容时，就需要多次系统调用来完成：首先调用 open() 打开文件，然后调用 read() 读取文件内容，并调用 write() 将内容写到标准输出，最后再调用 close() 关闭文件。

那么，系统调用的过程有没有发生 CPU 上下文的切换呢？答案自然是肯定的。

CPU 寄存器里原来用户态的指令位置，需要先保存起来。接着，为了执行内核态代码，CPU 寄存器需要更新为内核态指令的新位置。最后才是跳转到内核态运行内核任务。

而系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。*所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。*

不过，需要注意的是，系统调用过程中，并不会涉及到虚拟内存等进程用户态的资源，也不会切换进程。这跟我们通常所说的进程上下文切换是不一样的：

- 进程上下文切换，是指从一个进程切换到另一个进程运行；
- 系统调用过程中一直是同一个进程在运行。

所以，**系统调用过程通常称为特权模式切换，而不是上下文切换**。但实际上，系统调用过程中，CPU 的上下文切换还是无法避免的。

那么，进程上下文切换跟系统调用又有什么区别呢？

首先，进程是由内核来管理和调度的，进程的切换只能发生在内核态。所以，进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态。

因此，进程的上下文切换就比系统调用时多了一步：**在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的虚拟内存、栈等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈**。

如下图所示，保存上下文和恢复上下文的过程并不是“免费”的，需要内核在 CPU 上运行才能完成。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgursytudj30qu05674j.jpg)

另外，我们知道， Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在多处理器系统上，缓存是被多个处理器共享的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。

知道了进程上下文切换潜在的性能问题后，我们再来看，究竟什么时候会切换进程上下文。

显然，进程切换时才需要切换上下文，换句话说，只有在进程调度的时候，才需要切换上下文。Linux 为每个 CPU 都维护了一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，然后选择最需要 CPU 的进程，也就是优先级最高和等待 CPU 时间最长的进程来运行。

那么，进程在什么时候才会被调度到 CPU 上运行呢？

最容易想到的一个时机，就是进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行。

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行。
- 进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行。
- 当进程通过睡眠函数  sleep 这样的方法将自己主动挂起时，自然也会重新调度。
- 当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行。
- 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

### 线程上下文切换

线程与进程最大的区别在于，**线程是调度的基本单位，进程是资源拥有的基本单位**。说白了，所谓内核中的任务调度，实际上的调度对象是线程；而进程只是给线程提供了虚拟内存、全局变量等资源。所以，对于线程和进程，我们可以这么理解：

- 当进程只有一个线程时，可以认为进程就等于线程。
- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的。
- 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的。

这么一来，线程的上下文切换其实就可以分为两种情况：

第一种， 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。

第二种，前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。

虽然同为上下文切换，但同进程内的线程切换，要比多进程间的切换消耗更少的资源，而这，也正是多线程代替多进程的一个优势。

### 中断上下文切换

为了快速响应硬件的事件，**中断处理会打断进程的正常调度和执行**，转而调用中断处理程序，响应设备事件。而在打断其他进程时，就需要将进程当前的状态保存下来，这样在中断结束后，进程仍然可以从原来的状态恢复运行。

跟进程上下文不同，中断上下文切换并不涉及到进程的用户态。所以，即便中断过程打断了一个正处在用户态的进程，也不需要保存和恢复这个进程的虚拟内存、全局变量等用户态资源。中断上下文，其实只包括内核态中断服务程序执行所必需的状态，包括 CPU 寄存器、内核堆栈、硬件中断参数等。

**对同一个 CPU 来说，中断处理比进程拥有更高的优先级**，所以中断上下文切换并不会与进程上下文切换同时发生。同样道理，由于中断会打断正常进程的调度和执行，所以大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

另外，跟进程上下文切换一样，中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能。所以，当你发现中断次数过多时，就需要注意去排查它是否会给你的系统带来严重的性能问题。

### 查看系统的上下文切换情况

使用 `vmstat` 工具来查询系统的上下文切换情况。vmstat 是一个常用的系统性能分析工具，主要用来分析系统的内存使用情况，也常用来分析 CPU 上下文切换和中断的次数。

```c
# 每隔5秒输出1组数据
$ vmstat 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0      0 7005360  91564 818900    0    0     0     0   25   33  0  0 100  0  0
```

- **cs（context switch）**是每秒上下文切换的次数。
- **in（interrupt）**则是每秒中断的次数。
- **r（Running or Runnable）**是就绪队列的长度，也就是正在运行和等待 CPU 的进程数。
- **b（Blocked）**则是处于不可中断睡眠状态的进程数。

可以看到，这个例子中的上下文切换次数 cs 是 33 次，而系统中断次数 in 则是 25 次，而就绪队列长度 r 和不可中断状态进程数 b 都是 0。

vmstat 只给出了系统总体的上下文切换情况，要想查看每个进程的详细情况，就需要使用 `pidstat`  了。给它加上 -w 选项，就可以查看每个进程上下文切换的情况了。

```c
# 每隔5秒输出1组数据
$ pidstat -w 5
Linux 4.15.0 (ubuntu)  09/23/18  _x86_64_  (2 CPU)

08:18:26      UID       PID   cswch/s nvcswch/s  Command
08:18:31        0         1      0.20      0.00  systemd
08:18:31        0         8      5.40      0.00  rcu_sched
...
```

这个结果中有两列内容是我们的重点关注对象。一个是  **cswch**  ，表示每秒自愿上下文切换（voluntary context switches）的次数，另一个则是  **nvcswch**  ，表示每秒非自愿上下文切换（non voluntary context switches）的次数。

- 所谓**自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换**。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。
- 所谓**非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换**。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。