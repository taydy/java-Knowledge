# 内存

在我们日常使用的 Linux 或者 Windows 操作系统下，程序并不能直接访问物理内存。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2z5449fzj30vq0n4di6.jpg" style="zoom:50%;" />

内存被分成固定大小的页（Page），然后再通过虚拟内存地址（Virtual Address）到物理内存地址（Physical Address）的地址转换（Address Translation），才能到达实际存放数据的物理内存位置。而我们的程序看到的内存地址，都是虚拟内存地址。

## 简单页表

想要把虚拟内存地址，映射到物理内存地址，最直观的办法，就是来建一张映射表。这个映射表，能够实现虚拟内存里面的页，到物理内存里面的页的一一映射。这个映射表，在计算机里面，就叫作**页表**(Page Table)。

页表这个地址转换的办法，会把一个内存地址分成**页号**(Directory)和**偏移量**(Offset)两部分。



<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2zar9470j30yr0u042j.jpg" style="zoom:50%;" />

其实，前面的高位，就是内存地址的页号。后面的低位，就是内存地址里面的偏移量。做地址转换的页表，只需要保留虚拟内存地址的页号和物理内存地址的页号之间的映射关系就可以了。同一个页里面的内存，在物理层面是连续的。以一个页的大小是 4K 字节（4KB）为例，我们需要 20 位的高位，12 位的低位。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2zejyw4rj313r0u00v8.jpg" style="zoom:50%;" />

对于一个内存地址转换，其实就是这样三个步骤：

1. 把虚拟内存地址，切分成页号和偏移量的组合；
2. 从页表里面，查询出虚拟页号，对应的物理页号；
3. 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。



*32 位的内存地址空间，页表一共需要记录 2^20 个到物理页号的映射关系。这个存储关系，就好比一个 2^20 大小的数组。一个页号是完整的 32 位的 4 字节（Byte），这样一个页表就需要 4MB 的空间。如果每个进程都需要一个 4MB 的页表空间，那么内存占用就太大了！*

## 多级页表

在整个进程的内存地址空间，通常是“两头实、中间空”。在程序运行的时候，内存地址从顶部往下，不断分配占用的栈的空间。而堆的空间，内存地址则是从底部往上，是不断分配占用的。

所以，在一个实际的程序进程里面，虚拟内存占用的地址空间，通常是两段连续的空间。而不是完全散落的随机的内存地址。而多级页表，就特别适合这样的内存地址分布。

我们以一个 4 级的多级页表为例，来看一下。同样一个虚拟内存地址，偏移量的部分和上面简单页表一样不变，但是原先的页号部分，我们把它拆成四段，从高到低，分成 4 级到 1 级这样 4 个页表索引。



<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2z9u9lasj31jy0u0jw1.jpg" style="zoom:50%;" />

对应的，一个进程会有一个 4 级页表。我们先通过 4 级页表索引，找到 4 级页表里面对应的条目（Entry）。这个条目里存放的是一张 3 级页表所在的位置。4 级页面里面的每一个条目，都对应着一张 3 级页表，所以我们可能有多张 3 级页表。

找到对应这张 3 级页表之后，我们用 3 级索引去找到对应的 3 级索引的条目。3 级索引的条目再会指向一个 2 级页表。同样的，2 级页表里我们可以用 2 级索引指向一个 1 级页表。

而最后一层的 1 级页表里面的条目，对应的数据内容就是物理页号了。在拿到了物理页号之后，我们同样可以用“页号 + 偏移量”的方式，来获取最终的物理内存地址。

我们可能有很多张 1 级页表、2 级页表，乃至 3 级页表。但是，因为实际的虚拟内存空间通常是连续的，我们很可能只需要很少的 2 级页表，甚至只需要 1 张 3 级页表就够了。

事实上，多级页表就像一个多叉树的数据结构，所以我们常常称它为**叶表树**（Page Table Tree）。因为虚拟内存地址分布的连续性，树的第一层节点的指针，很多就是空的，也就不需要有对应的子树了。所谓不需要子树，其实就是不需要对应的 2 级、3 级的页表。找到最终的物理页号，就好像通过一个特定的访问路径，走到树最底层的叶子节点。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb2zk3s0qij30u00zfwmz.jpg" style="zoom:50%;" />

以这样的分成 4 级的多级页表来看，每一级如果都用 5 个比特表示。那么每一张某 1 级的页表，只需要 2^5=32 个条目。如果每个条目还是 4 个字节，那么一共需要 128 个字节。而一个 1 级索引表，对应 32 个 4KB 的也就是 128KB 的大小。一个填满的 2 级索引表，对应的就是 32 个 1 级索引表，也就是 4MB 的大小。

我们可以一起来测算一下，一个进程如果占用了 8MB 的内存空间，分成了 2 个 4MB 的连续空间。那么，它一共需要 2 个独立的、填满的 2 级索引表，也就意味着 64 个 1 级索引表，2 个独立的 3 级索引表，1 个 4 级索引表。一共需要 69 个索引表，每个 128 字节，大概就是 9KB 的空间。比起 4MB 来说，只有差不多 1/500。

不过，多级页表虽然节约了我们的存储空间，却带来了时间上的开销，所以它其实是一个“以时间换空间”的策略。原本我们进行一次地址转换，只需要访问一次内存就能找到物理页号，算出物理内存地址。但是，用了 4 级页表，我们就需要访问 4 次内存，才能找到物理页号了。

## 加速地址转换：TLB

内存访问其实比 Cache 要慢很多。我们本来只是要做一个简单的地址转换，现在反而要一下子多访问好多次内存。

程序所需要使用的指令，都顺序存放在虚拟内存里面。我们执行的指令，也是一条条顺序执行下去的。也就是说，我们对于指令地址的访问，存在“空间局部性”和“时间局部性”，而需要访问的数据也是一样的。我们连续执行了 5 条指令。因为内存地址都是连续的，所以这 5 条指令通常都在同一个“虚拟页”里。

因此，这连续 5 次的内存地址转换，其实都来自于同一个虚拟页号，转换的结果自然也就是同一个物理页号。

于是，计算机工程师们专门在 CPU 里放了一块缓存芯片。这块缓存芯片我们称之为 **TLB**，全称是**地址变换高速缓冲**(Translation-Lookaside Buffer)。这块缓存存放了之前已经进行过地址转换的查询结果。这样，当同样的虚拟地址需要进行地址转换的时候，我们可以直接在 TLB 里面查询结果，而不需要多次访问内存来完成一次转换。

TLB 和我们前面讲的 CPU 的高速缓存类似，可以分成指令的 TLB 和数据的 TLB，也就是 **ITLB** 和 **DTLB**。同样的，我们也可以根据大小对它进行分级，变成 L1、L2 这样多层的 TLB。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb30m8hueqj319g0u0tbi.jpg" style="zoom:50%;" />

为了性能，我们整个内存转换过程也要由硬件来执行。在 CPU 芯片里面，我们封装了**内存管理单元（MMU，Memory Management Unit）**芯片，用来完成地址转换。和 TLB 的访问和交互，都是由这个 MMU 控制的。

## 安全性与内存保护

进程的程序也好，数据也好，都要存放在内存里面。实际程序指令的执行，也是通过程序计数器里面的地址，去读取内存内的内容，然后运行对应的指令，使用相应的数据。

虽然我们现代的操作系统和 CPU，已经做了各种权限的管控。正常情况下，我们已经通过虚拟内存地址和物理内存地址的区分，隔离了各个进程。但是，无论是 CPU 这样的硬件，还是操作系统这样的软件，都太复杂了，难免还是会被黑客们找到各种各样的漏洞。

就像我们在软件开发过程中，常常会有一个“兜底”的错误处理方案一样，在对于内存的管理里面，计算机也有一些最底层的安全保护机制。这些机制统称为**内存保护**(Memory Protection)。

### 可执行空间保护

这个机制是说，我们对于一个进程使用的内存，只把其中的指令部分设置成“可执行”的，对于其他部分，比如数据部分，不给予“可执行”的权限。因为无论是指令，还是数据，在我们的 CPU 看来，都是二进制的数据。我们直接把数据部分拿给 CPU，如果这些数据解码后，也能变成一条合理的指令，其实就是可执行的。

这个时候，黑客们想到了一些搞破坏的办法。我们在程序的数据区里，放入一些要执行的指令编码后的数据，然后找到一个办法，让 CPU 去把它们当成指令去加载，那 CPU 就能执行我们想要执行的指令了。对于进程里内存空间的执行权限进行控制，可以使得 CPU 只能执行指令区域的代码。对于数据区域的内容，即使找到了其他漏洞想要加载成指令来执行，也会因为没有权限而被阻挡掉。

### 地址空间布局随机化

内存层面的安全保护核心策略，是在可能有漏洞的情况下进行安全预防。上面的可执行空间保护就是一个很好的例子。但是，内存层面的漏洞还有其他的可能性。

这里的核心问题是，其他的人、进程、程序，会去修改掉特定进程的指令、数据，然后，让当前进程去执行这些指令和数据，造成破坏。要想修改这些指令和数据，我们需要知道这些指令和数据所在的位置才行。

原先我们一个进程的内存布局空间是固定的，所以任何第三方很容易就能知道指令在哪里，程序栈在哪里，数据在哪里，堆又在哪里。这个其实为想要搞破坏的人创造了很大的便利。而地址空间布局随机化这个机制，就是让这些区域的位置不再固定，在内存空间随机去分配这些进程里不同部分所在的内存空间地址，让破坏者猜不出来。猜不出来呢，自然就没法找到想要修改的内容的位置。如果只是随便做点修改，程序只会 crash 掉，而不会去执行计划之外的代码。

<img src="https://tva1.sinaimg.cn/large/006tNbRwgy1gb30t7y2t9j30u00wz77h.jpg" style="zoom:50%;" />

## 页面回收算法

在 Linux 系统中，当内存有盈余时，内核会尽量多地使用内存作为文件缓存，从而提高系统的性能。文件缓存页面会加入文件类型的 LRU 链表中，当系统内存紧张时，文件缓存页面会被丢弃，或者被修改的文件缓存会被写回到存储设备中，与块设备同步之后便可释放出物理内存。

现在的应用程序越来越转向内存密集型，无论系统中有多少物理内存都是不够用的，因此 Linux 系统会使用存储设备当作交换分区，内核将很少使用的内存换出到交换分区，以便释放出物理内存，这个机制称为**页交换(Swapping)**，这些处理机制统称为**页面回收(Page Reclaim)**。

在操作系统的发展过程中，有很多页面交换算法，其中每个算法都有各自的优缺点。Linux 内核中采用的页交换算法主要是 LRU 算法和第二次机会法。

### LRU 算法

LRU 是 Least Recently Used（最近最少使用）的缩写。LRU 假定最近不使用的页在较短的时间内也不会频繁使用。在内存不足时，这些页面将成为被换出的候选者。内核使用双向链表来定义 LRU 链表，并且根据页面的类型分为 LRU_ANON 和 LRU_FILE。每种类型的活跃性分为活跃 LRU 和不活跃 LRU，所以内核中一共有如下 5 个 LRU 链表。

- 不活跃匿名页面链表 LRU_INACTIVE_ANON;
- 活跃匿名页面链表 LRU_ACTIVE_ANON;
- 不活跃文件映射页面链表 LRU_INACTIVE_FILE;
- 活跃文件映射页面链表 LRU_INACTIVE_FILE;
- 不可回收页面链表 LRU_UNEVICTABLE。

LRU 链表之所以要分成这样，是因为当内存紧缺时总是优先换出文件缓存页面，而不是匿名页面。大多数情况下文件缓存页面不需要回写磁盘，除非页面内容被修改了，而匿名页面总是要被写入交换分区才能被换出。

### 第二次机会法

在经典的 LRU 链表中，新产生的页面加入 LRU 链表的开头，将 LRU 链表中现存的页面向后移动一个位置。当系统内存短缺时，LRU 链表尾部的页面将会离开并被换出。当系统再需要这些页面时，这些页面会重新置于 LRU 链表的开头。显然，这个设计不是很巧妙，在换出页面时，没有考虑该页面是频繁使用，还是很少使用。也就是说，频繁使用的页面依然会因为在 LRU 链表末尾而被换出。

第二次机会算法的改进是为了避免把经常使用的页面置换出去。当选择置换页面时，依然和 LRU 算法一样，选择最早置入链表的页面，即在链表末尾的页面。

第二次机会法设置了一个**访问状态位（硬件控制的位）**，要检查页面的访问位。如果访问位是 0，就淘汰此页面；如果访问位是 1，就给它第二次机会，并选择下一个页面来换出。当该页面得到第二次机会时，它的访问位被清 0，如果该页在此期间被访问过，则访问位置 1。这样给了第二次机会的页面将不会被淘汰，直到所有其他页面被淘汰过或者也给了第二次机会。因此，如果一个页面经常被使用，其访问位总保持 1，就一直不会被淘汰出去。

Linux 内核使用 PG_active 和 PG_referenced 这两个标志位来实现第二次机会法。PG_active表示该页是否活跃，PG_referenced表示该页是否被引用过，主要函数如下：

- mark_page_accessed()
- page_referenced()
- page_check_references()

### OOM Killer 机制

当页面回收机制也不能满足页面分配器的需求时，OOM Killer 是最后一个杀手锏了。

它会选择占用内存比较高的进程来杀掉，从而释放出内存。

OOM Killer 机制提供了几个参数来调整进程在 OOM Killer 中的行为。

- **/proc/<pid>/oom_score_adj** 可以设置 -1000~1000 之间，当设置为 -1000 时，表示不会被 OOM Killer 选中；
- **/proc/<pid>/oom_adj** 它的值从 -17~15，值越大，越容易被 OOM Killer 选中；值越小，被选中的可能性越小。当值为 -17 时，表示进程永远不会被选中。这个 oom_adj 是要被 oom_score_adj 替代的，只是为了兼容旧内核版本暂时保留；
- **/proc/<pid>/oom_score** 表示当前进程的 oom 分数。

