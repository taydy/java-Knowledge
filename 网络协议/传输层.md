# 传输层

传输层里比较重要的两个协议，一个是 **TCP**，一个是 **UDP**。

**TCP 提供可靠交付**。通过 TCP 连接传输的数据，无差错、不丢失、不重复并且按序到达。而 **UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达**。

**TCP 是面向字节流的**。发送的时候发的是一个二进制流，没头没尾。而 **UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收**。

**TCP 是可以有拥塞控制的**。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。**UDP 就不会，应用让我发，我就发，管它洪水滔天。**

因而 **TCP 其实是一个有状态服务**，精确记录着发送了没有，接收到没有，发送到哪儿，应该接受哪个了。而 **UDP 则是无状态服务**。

## UDP

UDP 包格式如下所示：

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbadtoq1n5j30tz09fjs1.jpg)

UDP 有以下主要使用场景：

- 需要资源少，在网络比较好的内网或者对于丢包不敏感的应用；
- 不需要一对一沟通，建立连接，而是可以广播的应用；
- 需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。

## TCP

TCP 头格式如下所示：

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbadzzcyuxj30um0fljta.jpg)

首先，**源端口号和目标端口号**是不可少的，这一点和 UDP 是一样的。如果没有这两个端口号。数据就不知道应该发给哪个应用。

**序号是为了解决乱序的问题**。**确认序号是为了解决丢包的问题**。

TCP 是靠谱的协议，但是这不能说明它面临的网络环境好。从 IP 层面来讲，如果网络状况的确那么差，是没有任何可靠性保证的，而作为 IP 的上一层 TCP 也无能为力，唯一能做的就是更加努力，不断重传，通过各种算法保证。也就是说，对于 TCP 来讲，IP 层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性。

接下来是一些状态位。例如 **SYN 是发起一个连接**，**ACK 是回复**，**RST 是重新连接**，**FIN 是结束连接**。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。

还有一个重要的就是**窗口大小**。TCP 要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力，别发送的太快，也别发的太慢。

### 三次握手

TCP 的连接建立就是我们常常说的三次握手。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbaf380d46j30ep08yq3r.jpg)

一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。

三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是 **TCP 包的序号问题**。A 要告诉 B，我这面发起的包的序号起始是从哪个号开始的，B 同样也要告诉 A，B 发起的包的序号起始是从哪个号开始的。为什么序号不能都从 1 开始呢？因为这样往往会出现冲突。

*例如，A 连上 B 之后，发送了 1、2、3 三个包，但是发送 3 的时候，中间丢了，或者绕路了，于是重新发送，后来 A 掉线了，重新连上 B 后，序号又从 1 开始，然后发送 2，但是压根没想发送 3，但是上次绕路的那个 3 又回来了，发给了 B，B 自然认为，这就是下一个包，于是发生了错误。*

### 四次挥手

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbaf72ighij30fd0d93zs.jpg)

TCP 连接终止时，主机 1 先发送 FIN 报文，主机 2 进入 CLOSE_WAIT 状态，并发送一个 ACK 应答，同时，主机 2 通过 read 调用获得 EOF，并将此结果通知应用程序进行主动关闭操作，发送 FIN 报文。主机 1 在接收到 FIN 报文后发送 ACK 应答，此时主机 1 进入 TIME_WAIT 状态。

主机 1 在 TIME_WAIT 停留持续时间是固定的，是最长分节生命期 MSL（maximum segment lifetime）的两倍，一般称之为 2MSL。**2MSL 是从主机 1 接收到 FIN 后发送 ACK 开始计时的**。 和大多数 BSD 派生的系统一样，Linux 系统里有一个硬编码的字段，名称为 TCP_TIMEWAIT_LEN，其值为 60 秒。也就是说，**Linux 系统停留在 TIME_WAIT 的时间固定为 60 秒**。

**只有发起连接终止的一方会进入 TIME_WAIT 状态**



#### TIME_WAIT 有两点作用

1. 为了确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭；
2. 为了让旧连接的重复节点在网络中自然消失。

#### TIME_WAIT 的危害：

1. 内存资源占用，这个目前看来不是太严重，可以忽略；
2. 对端口资源的占用，一个 TCP 连接至少消耗一个本地端口。端口资源也是有限的，一般可以开启的端口为 32768~61000，也可以通过 `net.ipv4.ip_local_port_range` 指定，如果 TIME_WAIT 状态太多，会导致无法创建新连接。

#### 如何优化 TIME_WAIT ?

Linux 系统对于`net.ipv4.tcp_tw_reuse`的解释如下：

> Allow to reuse TIME-WAIT sockets for new connections when it is safe from protocol viewpoint. Default value is 0.It should not be changed without advice/request of technical experts.

这段话的大意是从协议角度理解如果是安全可控的，可以复用处于 TIME_WAIT 的套接字为新的连接所用。

那么什么是协议角度理解的安全可控呢？主要有两点：

1. 只适用于连接发起方（C/S 模型中的客户端）；
2. 对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复用。

使用这个选项，还有一个前提，需要打开对 TCP 时间戳的支持，即 `net.ipv4.tcp_timestamps=1` (默认即为 1)。

要知道，TCP 协议也在与时俱进，RFC 1323 中实现了 TCP 拓展规范，以便保证 TCP 的高可用，并引入了新的 TCP 选项，两个 4 字节的时间戳字段，用于记录 TCP 发送方的当前时间戳和从对端接收到的最新时间戳。由于引入了时间戳，我们在前面提到的 2MSL 问题就不复存在了，因为重复的数据包会因为时间戳过期被自然丢弃。



### 靠谱的传输协议

TCP 协议为了保证传输的顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是会应答某个之前的 ID，表示都收到了，这种模式称为**累计确认**或者**累计应答(Cumulative Acknowledgment)**。

对于记录所有发送的包和接手的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录。

- 发送了并且已经确认的；
- 发送了并且尚未确认的；
- 没有发送，但是已经等待发送的；
- 没有发送，并且暂时还不会发送的。

在 TCP 里，接收端会给发送端报一个窗口的大小，叫 **Advertised Window**。这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经发送了但是尚未确认加上等待发送的。超过这个窗口的，接收端就处理不过来。



于是，发送端需要保持下面的数据结构：

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbaxxmeiy5j30jw05u750.jpg)

- **LastByteAcked** 第一部分和第二部分的分界线；
- **LastByteSent** 第二部分和第三部分的分界线；
- **LastByteAcked + AdvertisedWindow** 第三部分和第四部分的分界线。



对于接收端来讲，它的缓存里记录的内容要简单一些。

- 接收并且确认过的；
- 还没接收，但是马上就能接收的；
- 还没接收，也没法接收的。

对应的数据结构就像这样：

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbaxxsis8rj30ke06n752.jpg)

- **MaxRcvBuffer** 最大缓存的量；
- **LastByteRead** 之后是已经接收了，但是还没被应用层读取的；
- **NextByteExpected** 是第一部分和第二部分的分界线。

第二部分的窗口有多大呢？

NextByteExpected 和 LastByteRead 的差其实是还没被应用层读取的部分占用掉的 MaxRcvBuffer 的量，我们定义为 A。

AdvertisedWindow 其实是 MaxRcvBuffer 减去 A。

也就是：`AdvertisedWindow = MaxRcvBuffer - ((NextByteExpected - 1) - LastByteRead)`。

那第二部分和第三部分的分界线在哪里呢？NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。

其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。

### 顺序问题与丢包问题

还是刚才的图，在发送端来看，1、2、3 已经发送并确认；4、5、6、7、8、9 都是发送了还没确认；10、11、12 是还没发出的；13、14、15 是接收方没有空间，不准备发的。

在接收端来看，1、2、3、4、5 是已经完成 ACK，但是没读取的；6、7 是等待接收的；8、9 是已经接收，但是没有 ACK 的。

发送端和接收端当前的状态如下：

- 1、2、3 没有问题，双方达成了一致；
- 4、5 接收方说 ACK 了，但是发送方还没收到，有可能丢了，有可能正在路上；
- 6、7、8、9 肯定都发了，8、9 已经到了，但是 6、7 没到，出现了乱序，缓存者但是没办法 ACK。

根据这个例子可以知道，顺序问题和丢包问题都有可能发生。那么来看一下**确认和重发机制**。

假设 4 的确认到了，不幸的是，5 的 ACK 丢了，6、7 的数据包丢了，这该怎么办呢？

一种方法就是**超时重试**，也即对每一个发送了但是没有 ACK 的包，都设一个定时器，超过了一定时间就重新尝试。这个超时时间不宜过短，时间必须大于往返时间 RTT，否则会引起不必要的重传，也不宜过长，这样超时时间变长，访问就变慢了。

估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为**自适应重传算法(Adaptive Retransmission Algorithm)**。

如果过一段时间，5、6、7 都超时了，就会重新发送。接收方发现 5 原来接收过，于是丢弃 5；6 收到了，发送 ACK，要求下一个是 7，7 不幸又丢了。当 7 再次超时的时候，有需要重传的时候，TCP 的策略是 **每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍**。

超时触发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？

有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的 ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

例如，接收方发现 6、8、9 都已经接收了，就是 7 没来，那肯定是丢了，于是发送三个 6 的 ACK，要求下一个是 7。客户端收到 3 个，就会发现 7 的确又丢了，不等超时，马上重发。

还有一种方式称为 **Selective Acknowledgment(SACK)**。这种方式需要在 TCP 头里加一个 SACK 的东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一下子就能看出来是 7 丢了。

### 流量控制问题

我们再来看流量控制机制，在对于包的确认中，同时会携带一个窗口的大小。

我们先假设窗口不变的情况，窗口始终为 9。4 的确认来的时候，会右移一个，这个时候第 13 个包也可以发送了。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb1p9yk37j30k206ijs7.jpg)

这个时候，假设发送端发送过猛，会将第三部分的 10、11、12、13 全部发送完毕，之后就停止发送了，未发送可发送部分为 0。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb1q2h2ekj30l406w3za.jpg)

当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb21unxlpj30l706uq3t.jpg)

如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。

我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不能再是 9 了，就要缩小一个变为 8。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb22m84z3j30k207qt9g.jpg)

这个新的窗口 8 通过 6 的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从 9 改成了 8。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb23has8oj30m606n3z6.jpg)

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb23vkbbkj30lk077js3.jpg)

当这个窗口通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，停止发送。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb24f86ptj30lw06u3z8.jpg)

如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

这就是我们常说的流量控制。

### 拥塞控制问题

最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，前面的滑动窗口 rwnd 是怕发送方把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满。

这里有一个公式 `LastByteSent - LastByteAcked <= min {cwnd, rwnd}` ，是拥塞窗口和滑动窗口共同控制发送的速度。

那发送方怎么判断网络是不是满呢？这其实是个挺难的事情，因为对于 TCP 协议来讲，他压根不知道整个网络路径都会经历什么，对他来讲就是一个黑盒。TCP 发送包常被比喻为往一个水管里面灌水，而 TCP 的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽。

水管有粗细，网络有带宽，也即每秒钟能够发送多少数据；水管有长度，端到端有时延。在理想状态下，水管里面水的量 = 水管粗细 x 水管长度。对于到网络上，通道的容量 = 带宽 × 往返延迟。

如果我们设置发送窗口，使得发送但未确认的包为通道的容量，就能够撑满整个管道。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb283emrcj30bw0fiwfg.jpg)

如图所示，假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024byte。已经过去了 8s，则 8 个包都发出去了，其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。5-8 后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为 8 个包，正好等于带宽，也即每秒发送 1 个包，乘以来回时间 8s。

如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？

我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。

这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。

于是 TCP 的拥塞控制主要来避免两种现象，**包丢失**和**超时重传**。一旦出现了这些现象就说明，发送速度太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢？

一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd 加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是指数性的增长。

涨到什么时候是个头呢？有一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。

每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，出现了拥塞。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将 sshresh 设为 cwnd/2，将 cwnd 设为 1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。

前面我们讲过**快速重传算法**。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb2gkdy1dj30pn0h1784.jpg)

就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，TCP 的拥塞控制主要来避免的两个现象都是有问题的。

1. 丢包并不代表者通道满了。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，其实是不对的；
2. TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这个时候已经晚了。其实 TCP 只要填满带宽就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了 **TCP BBR 拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb2kax0dnj30l60e477u.jpg)



## 套接字 Socket

Socket 变成进行的是端到端的通信，基于 TCP 和 UDP 协议。

在网络层，Socket 函数需要指定到底是 IPv4 还是 IPv6，分别对应设置为 AF_INET 和 AF_INET6。另外，还要指定到底是 TCP 还是 UDP。TCP 协议是基于数据流的，所以设置为 SOCK_STREAM，而 UDP 是基于数据报的，因而设置为 SOCK_DGRAM。

### 基于 TCP 协议的 Socket 程序函数调用过程

TCP 的服务端要先监听一个端口，一般是**调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口**。

当服务端有了 IP 和端口号，就可以**调用 listen 函数进行监听**。在 TCP 的状态图里面，有一个 listen 状态，当调用这个函数之后，服务端就进入了这个状态，这时候客户端就可以发起连接了。

在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完毕，处于 established 状态；一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态。

接下来，**服务端调用 accept 函数，拿出一个已经完成的连接进行处理**。如果还没有完成，就要等着。

在服务端等待的时候，**客户端可以通过 connect 函数发起连接**。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket。

> 注意，监听的 Socket 和真正用来传数据的 Socket 是两个，一个叫作**监听 Socket**，一个叫作**已连接 Socket**。

连接建立成功之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。

![基于 TCP 协议的 Socket 程序函数调用过程](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb6snztktj30sw0tan44.jpg)

说 TCP 的 Socket 就是一个文件流，是非常准确的。因为，Socket 在 Linux 中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。

在内核中，Socket 是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构 `task_struct`，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。

这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个 inode，只不过 Socket 对应的 inode 不像真正的文件系统一样保存在硬盘上，而是在内存中。在这个 inode 中，指向了 Socket 在内核中的 Socket 结构。

在这个结构中，主要是两个队列，一个是 **发送队列**，一个是 **接收队列**。在这两个队列里面保存的是一个个缓存 `sk_buff`。这个缓存里面能够看到完整的包结构。

![](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb703agoyj30oj0q6juj.jpg)

### 基于 UDP 协议的 Socket 程序函数调用过程

对于 UDP 来讲，过程有些不一样。UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen 和 connect，但是，UDP 的的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。

![基于 UDP 协议的 Socket 程序函数调用过程](https://tva1.sinaimg.cn/large/006tNbRwgy1gbb762vbsoj30su0powkh.jpg)